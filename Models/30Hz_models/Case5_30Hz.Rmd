---
title: "Case 5 with 30Hz frequency"
author: "Javad Khataei"
date: "11/05/2019"
output:
    html_document:
        code_folding : hide
        toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE , eval = T)
```

## Linear imputation, X, Y, Z axis, and Features

In this markdown, we use the linear imputed data. Only **Features created based on the vector magnitude of raw accelerometer data** variables are used for this model. We can apply the following models using the `ApplyModels` function from `BEAP` package:

- `RF`, Random Forest
- `LDA`, Linear Discriminant Analysis
- `NB`, Naive Bayes
- `SVM`, Support Vector Machines
- `KNN`, k-Nearest Neighbors
- `DT`, desicion Tree

 
## Read and prepare the data
```{r message=FALSE, warning=FALSE}

#import libraries
library(data.table)
library(tidyverse)
library(lubridate)
library(activityCounts)
library(magrittr)
library(scales)
library(caret)
library(stringr)
library(MLmetrics)
library(PRROC)
library(gridExtra)
library(kableExtra)
library(imputeTS)
library(Beap) # It's not on CRAN yet





# ---------------------------- Read the data ----------------------

# set the working directory to the folder that has the raw data and the intervals file
OS <- Sys.info()
if (OS["sysname"] == "Windows") {
  main_path <-
    "Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data"
} 
if (OS["sysname"] == "Linux") {

      main_path <-
    "/media/Z/Research/dfuller/Walkabilly/studies/smarphone_accel/data"
}

if (OS["sysname"] == "macOS") {
  main_path <-
    "/Volumes/hkr-storage/Research/dfuller/Walkabilly/studies/smarphone_accel/data"
}
# Read the file with x,y,z axis and labels.
Ethica_df <-
  fread(paste0(main_path,"/Ethica_Jaeger_Merged/pocket/pocket_with_couns_and_vec_meg_30Hz.csv"))


# ---------------------------- Prepare the data ----------------------------

# Only participant 112 is  not properly classified
working_df  <-
  Ethica_df %>% filter(!(participant_id %in% c(112)))


working_df %<>%  dplyr::select(c(x_axis, y_axis, z_axis, trimmed_activity))
working_df  %<>% filter(trimmed_activity != "transit")


# models canot work with strin
working_df$trimmed_activity  %<>% str_replace_all(" ", "_") %>%
  factor(
    levels = c(
      "Lying",
      "Sitting",
      "Self_Pace_walk",
      "Running_3_METs",
      "Running_5_METs",
      "Running_7_METs"
    )
  )


```

Note that we need to exclude Participant number 112  as it is not properly classified. 

## Create vector magnititude
```{r}
norm <- function(x,y,z) sqrt((x^2 + y^2 + z^2))
working_df[1:100,] %>% select(c(x_axis, y_axis, z_axis)) %>% 
    rowwise() %>% 
    mutate(vec_mag1 = norm(x_axis, y_axis, z_axis))

```



#NOTE : NEED TO MODIFY THE BEAP PACKAGE TO CALCCULATE FEATURE ONLY BASED ON VEC MAG
# Add new features
We use a window of one second.

```{r message= T , warning=FALSE}
frequency <- 30
window_size_sec <- 1
# The number of features reduces by this
reduction_coef <-  window_size_sec * frequency
new_features_df <-
  GenerateFeatures(raw_df = working_df,
                   window_size_sec = window_size_sec,
                   frequency = frequency) #%>%
  #dplyr::select(-c("dfr_x", "dfr_y", "dfr_z")) # Eliminates outliers ,i.e. ("dfr_x", "dfr_y", "dfr_z")


# Increase the frequency
new_features_df <-
  new_features_df[rep(1:nrow(new_features_df) , each = reduction_coef),]


# reduce the size of working_df to add new_features
working_df  %<>% slice(1:nrow(new_features_df))
##  
working_df <- bind_cols(working_df, new_features_df)
# some models cannpt train if there is any NA
working_df  %<>% na_interpolation(option =  "linear")

```
# Fixing the high accuracy issue
Since we have a dataset with 58 predictive features and 55 of these features are constant for every 30 readings, we have a leaky training set. The window is one second, and the frequency is 30Hz. Therefore every 30 readings have the same features. To fix this issue, we only use the first observation in each window. Also, the size of the dataset will be smaller, and the modelling process will be faster. 


```{r}

freq <- reduction_coef

working_df  %<>% groupdata2::group(n = freq, method = "greedy") %>%
  rename( "id" = .groups )

working_df  %<>% group_by(id) %>%
  summarise_all(first) %>% 
  select(-id)

```


## Apply models
```{r message=TRUE, warning=FALSE}
results <-
    Beap::ApplyModels(
        working_df = working_df,
        model_names = c("RF"), #c("RF", "LDA", "NB", "SVM", "KNN", "DT")
        split_ratio = 0.7,
        shrink = 1,
        return_plots = TRUE,
        save_results = FALSE,min_node_size = 5
        
    )
```



## Compare the results


```{r message=FALSE, warning=FALSE}
print(results$Plots)

results$`Model-Accuracy` %>%  
  select(Accuracy, AUC, prAUC, Mean_F1, Mean_Sensitivity, Mean_Specificity) %>% 
  round(digits = 4) %>% 
    kable(label = " Accuracy for each model") %>%
    kable_styling(full_width = T, bootstrap_options = c("striped", "hover"))
 

#save(results, "Case3_reults.RData")
```

### Feature importance for RF

```{r}


imp_table <- results$RF_Feature_Importance$importance

row_names <- rownames(imp_table)

imp_table  %>% data.frame(row_names, .) %>% 
  arrange(desc(Overall) ) %>% 
  kable(label = " Top ten important features for RF model") %>%
    kable_styling(full_width = T, bootstrap_options = c("striped", "hover"))

```

